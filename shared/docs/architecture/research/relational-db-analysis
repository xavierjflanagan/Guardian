1. Some things in healthcare documentation are not permanent and that needs to be taken into account when designing the back end code pathways; allergies can be proved wrong or removed or resolved. So upon the receival of newer documentation, some health data may be supeceeded through newer information, or annoyingly the absense of information (the absence of a medication on a active medication list suggests the previous medication that was present on older documentaiton has now been stopped. Another example, is a new doc containing a revised allergy list that no longer has a allergy listed, in this case the patients app db would show paracetamol as an allergy, but this newer documentaiton states (though absence) that it is no loner an allergy). This all needs to be taken into account when designing our DB and front end architecture. this all may be taken care of by having a 'history of allergies' as well as a 'active allergies' table/labelling system - so an allergy ever entering db remains there forever and will show up forever within the 'history of allergies' table. 
2. A single data point will have multple forms as it passes through the pipeline; raw image form, OCR extract form, AI JSON output, nromalized json output form. I want all these forms to be viewaable at the click of a button. This is especially important for confirming data integrity/accuracy (kind of like the ___ of a expensive of art that has gone through the hands of multiple buyers, to help confirm its authenticity)
3. Geographic location on that raw image, it would be great if, you could click on a piece of data on the user side dashboard, and be presented with the option to view source of entire original raw file, but also a zoomed cropped image of the exact data point, and maybe also the accompanying ahdacent contextual data, on the original raw file. For example lets say there is a data point on the dashboard about the patient having anemia. that piece of info actually came from within the 'esay' component of a doctor letter whihc stated within a sentence that the patient has anemia. So when you click on the 'anemia' conditon that is listed on the dashboard under the 'medical conditions' heading/table, it shows you the 'source information' with a few options of what you can see: A) the original file name - which you can click on to immediately view the file in entirety. B) the zoomed in version of the above through either sowing the cropped zoomed in part of the raw file, or maybe just the text itself from the image "...has anemia due to mennorhagia for the past couple of years as confirmed by blood test result...". C) the OCR text extract D) JSONB output. E) cleaned JSONB output. 
4. What i see as really important adn integral here is the labelling and metadata attached to each health data point within the relational DB. If that is all very rich, then the front end only needs to go: 'okay lets list all data points that have 'allergy' as a tag',  and then just pulls the data that is tagged with allergy to fill that section of the dashboard. Then if we want (and we will do this) we can go a level deeper on allergies and get the front end to instead have mu;tiple sub categories within allergy to show on the dashboard (such as active or not, reason for why no longer; resolved or documentation or diagnostic error etc). 
5. the metadata ought to be extensive, i assume the AI model creating the messy jSONB will create a lot of metadata to attach to each data point extracted from the raw file - some of that metadata will be contextual metadata that talks about adhacent health data that was attached to that data point (in my anemia example, hence you would add contextual data alongisde it "due to menorrhagia",. but the AI should also generate a lot of its own metadata, such as the date that the file was ingested and therefore date of ingestion into the dashboard, the date attached to the document (if present, such as the date at the top of the doctors letter), the date of first diagnoses of anemia (if present on the raw file), management and treatment of anemia (if present, also adding any metadata about whether any listed management practices is active, past, future), metadata about authentication (was this letter that mentioned anemia by a doctor and therefore autheniticated/verififed/high-regarded, or was it a letter from the pateints mum to their school teacher... for example). And also any other metadata that the AI deems important. 
5. Is it possible to have the AI link metadata tags/columns: for example, a medication is extracted from an upload file, the contextual data attached is that it is for X condition. So this relationship is tracked. For this file, two rows might be created: one for the medication and one for a condition ('X'). They should each be linked to each other. So on the user side dashboard, you click on the medication and it lists why the medication is being taken and importantly shows the condition, but even better the condition actually has a hyperlink or something that takes you to that condition within the conditions list section of the dashboard (or has a in wondow pop up, or a simple inline dropdown). The UX and layout or happening on the user dashboard worry me less, but concerns/interests me more is how this performs on the DB side. How i see it working is that two rows are simply created for the two core pieces of health data; the medication, and the condition. The AI picks up on the relationship and so for the condition it lists the medication under treatments, and for the medication row it lists the condition under the 'used for..' section. And then each row has a hyperlink to the opposing row. 