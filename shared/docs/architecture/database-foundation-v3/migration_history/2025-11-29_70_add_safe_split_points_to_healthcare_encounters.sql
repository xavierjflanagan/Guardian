-- ============================================================================
-- Migration 70: Add safe_split_points Column to healthcare_encounters
-- Date: 2025-11-29
-- Issue: Pass 1 Strategy-A needs per-encounter safe-split points for batching
--
-- PROBLEM:
-- - safe_split_points are generated by Pass 0.5 AI and stored in pass05_chunk_results
-- - Reconciler aggregates them to shell_files.page_separation_analysis (file-level)
-- - BUT: Pass 1 needs per-ENCOUNTER safe-splits, not per-file
-- - A shell_file may contain multiple encounters, each needs only splits within its page range
--
-- SOLUTION:
-- - Add safe_split_points JSONB column to healthcare_encounters
-- - Update reconcile_pending_to_final RPC to accept and store safe_split_points
-- - Update reconciler TypeScript to filter splits per encounter's page range
--
-- AFFECTED TABLES: healthcare_encounters
-- AFFECTED FUNCTIONS: reconcile_pending_to_final()
--
-- SOURCE OF TRUTH SCHEMA TO UPDATE:
--   [x] current_schema/03_clinical_core.sql - Add column after position_confidence
--   [x] current_schema/08_job_coordination.sql - Update RPC function
--
-- DOWNSTREAM UPDATES REQUIRED:
--   [x] pending-reconciler.ts - Filter safe_split_points per encounter page range
--   [x] pending-reconciler.ts - Include in encounterData passed to RPC
--
-- RELATED DESIGN DOCS:
--   - PASS1-STRATEGY-A-MASTER.md Phase 0 Prerequisites
--   - 05-hierarchical-observability-system.md
--
-- ============================================================================

-- PART 1: Add Column to healthcare_encounters
-- ============================================================================

ALTER TABLE healthcare_encounters
ADD COLUMN IF NOT EXISTS safe_split_points JSONB DEFAULT NULL;

COMMENT ON COLUMN healthcare_encounters.safe_split_points IS
  'Migration 70: Consolidated safe-split points for this encounter only. Array of {page, split_type, marker, split_y, confidence} objects filtered from shell_files.page_separation_analysis based on encounter page range. Used by Pass 1/2 for batching large encounters.';

-- Index for queries that check if encounters have safe splits
CREATE INDEX IF NOT EXISTS idx_encounters_safe_splits
ON healthcare_encounters USING GIN (safe_split_points)
WHERE safe_split_points IS NOT NULL;


-- PART 2: Update reconcile_pending_to_final RPC
-- ============================================================================

CREATE OR REPLACE FUNCTION reconcile_pending_to_final(
  p_pending_ids UUID[],
  p_patient_id UUID,
  p_shell_file_id UUID,
  p_encounter_data JSONB
) RETURNS UUID AS $$
DECLARE
  v_encounter_id UUID;
  v_pending_id UUID;
  v_cascade_id TEXT;
BEGIN
  -- Migration 57: Get cascade_id from first pending
  SELECT cascade_id INTO v_cascade_id
  FROM pass05_pending_encounters
  WHERE id = p_pending_ids[1];

  -- Insert final encounter atomically (EXTENDED with safe_split_points - Migration 70)
  INSERT INTO healthcare_encounters (
    patient_id,
    source_shell_file_id,
    encounter_type,
    encounter_start_date,
    encounter_end_date,
    encounter_timeframe_status,
    date_source,
    provider_name,
    facility_name,
    facility_address,              -- Migration 66: Facility address
    start_page,
    start_boundary_type,
    start_marker,              -- Migration 53: Fixed from start_text_marker
    start_marker_context,
    start_region_hint,
    start_text_y_top,
    start_text_height,
    start_y,
    end_page,
    end_boundary_type,
    end_marker,                -- Migration 53: Fixed from end_text_marker
    end_marker_context,
    end_region_hint,
    end_text_y_top,
    end_text_height,
    end_y,
    position_confidence,
    safe_split_points,         -- Migration 70: Per-encounter safe splits for Pass 1/2 batching
    page_ranges,
    pass_0_5_confidence,
    summary,
    identified_in_pass,
    source_method,
    is_real_world_visit,
    data_quality_tier,
    quality_criteria_met,
    quality_calculation_date,
    encounter_source,
    created_by_user_id,
    -- Migration 57: Audit trail and tracking fields
    reconciled_from_pendings,
    chunk_count,
    cascade_id,
    completed_at,
    -- Migration 58: Identity fields
    patient_full_name,
    patient_date_of_birth,
    patient_address,
    chief_complaint
  )
  SELECT
    p_patient_id,
    p_shell_file_id,
    (p_encounter_data->>'encounter_type')::VARCHAR,
    (p_encounter_data->>'encounter_start_date')::TIMESTAMPTZ,
    (p_encounter_data->>'encounter_end_date')::TIMESTAMPTZ,
    (p_encounter_data->>'encounter_timeframe_status')::VARCHAR,
    (p_encounter_data->>'date_source')::VARCHAR,
    (p_encounter_data->>'provider_name')::VARCHAR,
    (p_encounter_data->>'facility_name')::VARCHAR,
    (p_encounter_data->>'facility_address')::VARCHAR,  -- Migration 66: Facility address
    (p_encounter_data->>'start_page')::INTEGER,
    (p_encounter_data->>'start_boundary_type')::VARCHAR,
    (p_encounter_data->>'start_text_marker')::VARCHAR,
    (p_encounter_data->>'start_marker_context')::VARCHAR,
    (p_encounter_data->>'start_region_hint')::VARCHAR,
    (p_encounter_data->>'start_text_y_top')::INTEGER,
    (p_encounter_data->>'start_text_height')::INTEGER,
    (p_encounter_data->>'start_y')::INTEGER,
    (p_encounter_data->>'end_page')::INTEGER,
    (p_encounter_data->>'end_boundary_type')::VARCHAR,
    (p_encounter_data->>'end_text_marker')::VARCHAR,
    (p_encounter_data->>'end_marker_context')::VARCHAR,
    (p_encounter_data->>'end_region_hint')::VARCHAR,
    (p_encounter_data->>'end_text_y_top')::INTEGER,
    (p_encounter_data->>'end_text_height')::INTEGER,
    (p_encounter_data->>'end_y')::INTEGER,
    (p_encounter_data->>'position_confidence')::NUMERIC,
    (p_encounter_data->'safe_split_points')::JSONB,    -- Migration 70: Safe split points (JSONB, not text)
    -- Migration 55: Proper JSONB array to PostgreSQL array conversion
    (SELECT ARRAY(
      SELECT ARRAY[(elem->0)::INTEGER, (elem->1)::INTEGER]
      FROM jsonb_array_elements(p_encounter_data->'page_ranges') AS elem
    )),
    (p_encounter_data->>'pass_0_5_confidence')::NUMERIC,
    (p_encounter_data->>'summary')::TEXT,
    'pass_0_5'::VARCHAR,
    'ai_pass_0_5'::VARCHAR,
    (p_encounter_data->>'is_real_world_visit')::BOOLEAN,
    (p_encounter_data->>'data_quality_tier')::VARCHAR,
    (p_encounter_data->'quality_criteria_met')::JSONB,
    NOW(),
    'shell_file'::VARCHAR,
    (p_encounter_data->>'created_by_user_id')::UUID,
    -- Migration 57: Audit trail and tracking fields
    cardinality(p_pending_ids),
    (SELECT COUNT(DISTINCT chunk_number)
     FROM pass05_pending_encounters
     WHERE id = ANY(p_pending_ids)),
    v_cascade_id,
    NOW(),
    -- Migration 58: Identity fields (extracted from JSONB)
    (p_encounter_data->>'patient_full_name')::TEXT,
    (p_encounter_data->>'patient_date_of_birth')::DATE,
    (p_encounter_data->>'patient_address')::TEXT,
    (p_encounter_data->>'chief_complaint')::TEXT
  RETURNING id INTO v_encounter_id;

  -- Mark all pendings as completed (atomic with insert)
  FOREACH v_pending_id IN ARRAY p_pending_ids
  LOOP
    UPDATE pass05_pending_encounters
    SET
      status = 'completed',
      reconciled_to = v_encounter_id,
      reconciled_at = NOW(),   -- Migration 57: Add reconciliation timestamp
      updated_at = NOW()
    WHERE id = v_pending_id;
  END LOOP;

  -- Update page assignments (atomic)
  -- Migration 56 FIX: Use subquery to match TEXT pending_id with UUID[] p_pending_ids
  UPDATE pass05_page_assignments
  SET
    encounter_id = v_encounter_id,
    reconciled_at = NOW()
  WHERE pending_id IN (
    SELECT pending_id
    FROM pass05_pending_encounters
    WHERE id = ANY(p_pending_ids)
  );

  RETURN v_encounter_id;
END;
$$ LANGUAGE plpgsql;


-- ============================================================================
-- DOWNSTREAM CODE CHANGES REQUIRED
-- ============================================================================

-- 1. pending-reconciler.ts - Add safe_split_points filtering and passing
--
-- In reconcileCascade() or where encounterData is built, add:
--
--   // Filter safe_split_points for this encounter's page range
--   const encounterSafeSplits = filterSafeSplitsForEncounter(
--     allSafeSplitPoints,
--     firstPending.start_page,
--     lastPending.end_page
--   );
--
--   const encounterData = {
--     ...existingFields,
--     safe_split_points: encounterSafeSplits,  // Migration 70
--   };
--
-- Add helper function:
--
--   function filterSafeSplitsForEncounter(
--     allSplits: any[],
--     startPage: number,
--     endPage: number
--   ): any[] {
--     if (!allSplits || allSplits.length === 0) return [];
--     return allSplits.filter(split => {
--       const splitPage = split.page ?? split.between_pages?.[0] ?? 0;
--       return splitPage >= startPage && splitPage <= endPage;
--     });
--   }

-- 2. current_schema/03_clinical_core.sql - Add column documentation
--
-- After line 579 (position_confidence), add:
--   safe_split_points JSONB, -- Migration 70: Per-encounter safe-split points for Pass 1/2 batching

-- 3. current_schema/08_job_coordination.sql - Update RPC function
--
-- Add safe_split_points to INSERT column list and SELECT values


-- ============================================================================
-- MIGRATION STATUS
-- ============================================================================
-- Date Started: 2025-11-29
-- Date Completed: 2025-11-29
--
-- EXECUTION CHECKLIST:
--   [x] Execute Part 1 (ALTER TABLE) via mcp__supabase__apply_migration
--   [x] Execute Part 2 (RPC function) via mcp__supabase__apply_migration
--   [x] Update current_schema/03_clinical_core.sql (source of truth)
--   [x] Update current_schema/08_job_coordination.sql (source of truth)
--   [x] Update pending-reconciler.ts (filter and pass safe_split_points)
--   [ ] Deploy worker to Render.com
--   [ ] Verify with test document upload
--
