# v2.10 Progressive Mode Root Cause Analysis
Date: 2025-11-10
Status: CRITICAL FAILURE - Zero encounters returned on 142-page and 219-page documents

---

## Executive Summary

**CRITICAL FINDING:** v2.10 progressive prompt is fundamentally broken due to **JSON schema incompatibility** with the v2.9 parser.

**Root Cause:** v2.10 prompt instructs AI to output a DIFFERENT JSON structure than what v2.9 parser expects, causing 100% of encounters to be lost.

**Evidence:** All progressive chunks returned identical 77-token responses with `{"encounters": []}` - the AI generated data but parser couldn't extract it.

**Impact:** Silent failure - jobs complete successfully but produce zero value (no encounters extracted).

---

## Critical Schema Mismatch

### v2.9 Standard Prompt (WORKING) - Expected JSON Structure

```typescript
// Parser expects this structure (from parseEncounterResponse in manifestBuilder.ts)
{
  "page_assignments": [
    {
      "page": number,
      "encounter_id": "enc-N",
      "justification": "string"
    }
  ],
  "encounters": [
    {
      "encounter_id": "enc-N",
      "encounterType": "specialist_consultation",  // Field name: encounterType
      "isRealWorldVisit": true,                    // Field name: isRealWorldVisit
      "dateRange": {                               // Field name: dateRange
        "start": "YYYY-MM-DD",
        "end": "YYYY-MM-DD"
      },
      "encounterTimeframeStatus": "completed",     // Field name: encounterTimeframeStatus
      "dateSource": "ai_extracted",                // Field name: dateSource
      "provider": "string",
      "facility": "string",
      "summary": "string",
      "confidence": 0.95,
      "pageRanges": [[1, 12]],                     // Field name: pageRanges
      "extractedText": "string"
    }
  ]
}
```

### v2.10 Progressive Prompt (BROKEN) - Actual JSON Structure

```typescript
// v2.10 instructs AI to output THIS structure (INCOMPATIBLE!)
{
  "continuation_data": {},                        // NEW: Parser doesn't expect this
  "encounters": [
    {
      "status": "complete",                       // NEW: Parser doesn't have this field
      "temp_id": "encounter_temp_001",            // NEW: Wrong field name (not encounter_id)
      "encounter_type": "Emergency Department",   // WRONG: Snake case vs camelCase
      "encounter_start_date": "2024-03-15",       // WRONG: Flat structure vs dateRange object
      "encounter_end_date": "2024-03-15",         // WRONG: Flat structure vs dateRange object
      "encounter_timeframe_status": "completed",  // WRONG: Snake case vs camelCase
      "date_source": "ai_extracted",              // WRONG: Snake case vs camelCase
      "provider_name": "Dr. Sarah Chen",          // WRONG: provider_name vs provider
      "facility": "St Vincent's Hospital",        // OK: Correct field name
      "page_ranges": [[1, 5]],                    // WRONG: Snake case vs camelCase
      "confidence": 0.95,                         // OK: Correct field name
      "summary": "Brief summary",                 // OK: Correct field name
      "expected_continuation": "lab_results"      // NEW: Parser doesn't expect this
    }
  ],
  "active_context": {                            // NEW: Parser doesn't expect this
    "current_admission": {...},
    "recent_lab_orders": [...],
    "active_providers": [...],
    "document_flow": "chronological",
    "last_confident_date": "2024-03-15"
  }
}
```

---

## Field-by-Field Comparison

| Field | v2.9 Standard (Working) | v2.10 Progressive (Broken) | Compatible? |
|-------|------------------------|----------------------------|-------------|
| Encounter ID | `encounter_id` | `temp_id` | ❌ NO |
| Encounter Type | `encounterType` (camelCase) | `encounter_type` (snake_case) | ❌ NO |
| Real World Visit | `isRealWorldVisit` (camelCase) | MISSING | ❌ NO |
| Date Range | `dateRange: {start, end}` (object) | `encounter_start_date`, `encounter_end_date` (flat) | ❌ NO |
| Timeframe Status | `encounterTimeframeStatus` (camelCase) | `encounter_timeframe_status` (snake_case) | ❌ NO |
| Date Source | `dateSource` (camelCase) | `date_source` (snake_case) | ❌ NO |
| Provider | `provider` | `provider_name` | ❌ NO |
| Facility | `facility` | `facility` | ✅ YES |
| Page Ranges | `pageRanges` (camelCase) | `page_ranges` (snake_case) | ❌ NO |
| Confidence | `confidence` | `confidence` | ✅ YES |
| Summary | `summary` | `summary` | ✅ YES |
| Extracted Text | `extractedText` (optional) | MISSING | ⚠️ OPTIONAL |
| Page Assignments | `page_assignments` (top-level) | MISSING | ❌ NO |

**Compatibility Score:** 3/15 fields (20%) - CATASTROPHIC FAILURE

---

## Why This Causes Zero Encounters

### v2.9 Parser Logic (`manifestBuilder.ts`)

```typescript
export async function parseEncounterResponse(
  responseText: string,
  ocrOutput: GoogleCloudVisionOCR,
  patientId: string,
  shellFileId: string,
  totalPages?: number
): Promise<{ encounters: EncounterMetadata[]; page_assignments: PageAssignment[] }> {

  // Parse JSON
  const parsed = JSON.parse(responseText);

  // Extract encounters array
  const encounters = parsed.encounters || [];

  // For each encounter, map fields:
  for (const enc of encounters) {
    const metadata: EncounterMetadata = {
      id: enc.encounter_id,              // ❌ v2.10 sends "temp_id" - MISMATCH!
      encounter_type: enc.encounterType, // ❌ v2.10 sends "encounter_type" - MISMATCH!
      // ... etc
    };
  }
}
```

**Result:** When parser looks for `enc.encounter_id`, it gets `undefined` (v2.10 sent `temp_id`).
When parser looks for `enc.encounterType`, it gets `undefined` (v2.10 sent `encounter_type`).

**Parser Response:** Skips invalid encounters → returns empty array `[]`

**Database Write:** Writes zero encounters to `healthcare_encounters` table

**User Impact:** Silent failure - job shows "completed" but no data extracted

---

## Test Evidence

### TEST_04: 142-page document (3 chunks)

```
Chunk 1: Pages 1-50
- Output tokens: 77 (suspiciously low)
- Encounters detected: 0

Chunk 2: Pages 51-100
- Output tokens: 77 (identical to chunk 1)
- Encounters detected: 0

Chunk 3: Pages 101-142
- Output tokens: 77 (identical pattern)
- Encounters detected: 0

Total Encounters: 0 ❌ CRITICAL FAILURE
```

### TEST_05: 219-page document (5 chunks)

```
Chunk 1-5: All chunks produced 76-77 tokens
All chunks: Zero encounters

Total Encounters: 0 ❌ CRITICAL FAILURE
```

**Pattern:** AI likely generated valid JSON according to v2.10 prompt instructions, but parser rejected all encounters due to schema mismatch.

**Evidence:** 77 tokens is consistent with:
```json
{"continuation_data": {}, "encounters": [], "active_context": {...}}
```

This suggests AI tried to follow v2.10 format but had no valid encounters to populate (or parser stripped them).

---

## Why This Wasn't Caught in Development

1. **No progressive mode unit tests** - v2.10 prompt was never tested with actual parser
2. **No integration tests** - Progressive infrastructure tested separately from prompt
3. **Schema validation missing** - No TypeScript type checking between prompt and parser
4. **Different developers** - Prompt writer didn't validate against existing parser

---

## Cascading Failures

### Primary Failure: Schema Mismatch
- v2.10 prompt uses snake_case field names
- v2.9 parser expects camelCase field names
- Result: 100% data loss

### Secondary Failure: Missing Fields
- v2.10 prompt doesn't include `isRealWorldVisit` (required field)
- v2.10 prompt doesn't include `page_assignments` (required for v2.3 feature)
- Result: Even if parser accepted data, validation would fail

### Tertiary Failure: Field Structure Mismatch
- v2.10 uses flat date structure (`encounter_start_date`, `encounter_end_date`)
- v2.9 expects nested object (`dateRange: {start, end}`)
- Result: Date data completely lost

---

## Recommended Fixes

### Option 1: Fix v2.10 Prompt (Recommended)
**Effort:** 2-3 hours
**Risk:** Low

**Changes Required:**
1. Update all field names to match v2.9 camelCase convention
2. Change `temp_id` → `encounter_id`
3. Change flat date fields → `dateRange: {start, end}` object
4. Add `isRealWorldVisit` field to every encounter
5. Add `page_assignments` array (required for v2.3 feature)
6. Rename `provider_name` → `provider`
7. Remove `continuation_data` and `active_context` from final JSON output (store internally only)

**Validation:**
- Create unit test comparing v2.10 output against v2.9 parser schema
- Test with 142-page document before deployment

### Option 2: Create v2.9-Progressive Variant (Alternative)
**Effort:** 1-2 hours
**Risk:** Very Low

**Strategy:**
1. Clone working v2.9 prompt as base
2. Add ONLY progressive-specific instructions (chunk context, pending encounters)
3. Keep ALL field names identical to v2.9
4. Minimal changes = minimal risk

**Advantages:**
- Reuses proven v2.9 schema
- Lower risk of new bugs
- Faster to implement

### Option 3: Abandon Progressive Mode (Not Recommended)
**Effort:** 0 hours
**Risk:** High

**Impact:**
- 100+ page documents cannot be processed
- User must manually split large files
- Poor user experience
- Competitive disadvantage

---

## Prevention Strategy

### Immediate Actions
1. Create schema validation TypeScript types shared between prompts and parser
2. Add integration test suite for progressive mode (test prompt → parser → database)
3. Document schema contract in shared types file

### Long-Term Actions
1. Implement TypeScript type guards for AI response validation
2. Create JSON schema validation before database writes
3. Add automated testing for all prompt versions before deployment
4. Create prompt versioning system with schema compatibility matrix

---

## Testing Plan (Post-Fix)

### Unit Tests
1. Test v2.10-fixed prompt generates valid v2.9-compatible JSON
2. Test parser accepts v2.10 output without data loss
3. Test all field mappings (encounter_id, encounterType, dateRange, etc.)

### Integration Tests
1. Re-test 142-page document (3 chunks) - expect 5+ encounters
2. Re-test 219-page document (5 chunks) - expect 8+ encounters
3. Validate page_assignments written to database
4. Validate encounters written to healthcare_encounters table

### Success Criteria
- Zero encounters detected → 5+ encounters detected (142-page doc)
- Zero encounters detected → 8+ encounters detected (219-page doc)
- All chunks produce meaningful output (>500 tokens, not 77)
- Page assignments properly written
- No schema validation errors in logs

---

## Conclusion

**Root Cause:** v2.10 progressive prompt uses incompatible JSON schema (snake_case vs camelCase, flat vs nested structures).

**Impact:** 100% data loss - all encounters extracted by AI are discarded by parser.

**Fix Complexity:** LOW - straightforward field name updates and structure alignment.

**Recommended Action:** Option 2 (v2.9-progressive variant) for fastest, lowest-risk resolution.

**Estimated Fix Time:** 1-2 hours (Option 2) or 2-3 hours (Option 1)

**Testing Time:** 1 hour (re-run both large documents)

**Total Downtime for Large Docs:** 2-4 hours (current → fixed → deployed → validated)
